{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code_example_schuler_baseline_various_mixes-v2.7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "monitor='val_accuracy'\n",
        "epochs=30\n",
        "batch_size=16\n",
        "input_shape=(128, 128, 3) # please resize it to (224,224,3) if you have enough RAM\n",
        "Verbose=True"
      ],
      "metadata": {
        "id": "6DH0gsiwyxgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXWocLnz38N"
      },
      "source": [
        "This source code requires a **HIGH RAM** machine.\n",
        "\n",
        "You might need to install this on your system:\n",
        "\n",
        "apt-get install python3-opencv git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQKpflNl7m63"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('k'):\n",
        "  !git clone https://github.com/joaopauloschuler/k-neural-api.git k\n",
        "else:\n",
        "  !cd k && git pull\n",
        "\n",
        "!cd k && pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWmCCX96ndE"
      },
      "source": [
        "import sys\n",
        "print(\"Python version\")\n",
        "print (sys.version)\n",
        "print(\"Version info.\")\n",
        "print (sys.version_info)\n",
        "\n",
        "import skimage\n",
        "print('skimage version',  skimage.__version__)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "import cai\n",
        "import cai.datasets\n",
        "import cai.densenet\n",
        "import cai.util\n",
        "import cai.models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WqdOtor61VZ"
      },
      "source": [
        "url_zip_file=\"https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/file_downloaded\"\n",
        "local_zip_file=\"plant_leaf.zip\"\n",
        "expected_folder_name=\"plant_leaf\"\n",
        "cai.datasets.download_zip_and_extract(\n",
        "    url_zip_file=url_zip_file, local_zip_file=local_zip_file, \n",
        "    expected_folder_name=expected_folder_name, Verbose=Verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yn9mmLAxvlK"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.utils.class_weight\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2LGtzGBx5IR"
      },
      "source": [
        "!rm -r plant_leaf/Plant_leave_diseases_dataset_without_augmentation/Background_without_leaves -R\n",
        "data_dir = \"plant_leaf/Plant_leave_diseases_dataset_without_augmentation/\"\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUfiL_BgqOct"
      },
      "source": [
        "def compiled_two_path_inception_v3(\n",
        "  classes=1000, \n",
        "  input_shape=input_shape,\n",
        "  two_paths_first_block=False,\n",
        "  two_paths_second_block=False,\n",
        "  max_mix_idx=10):\n",
        "  base_model = cai.models.two_path_inception_v3(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling=None,\n",
        "    two_paths_first_block=two_paths_first_block,\n",
        "    two_paths_second_block=two_paths_second_block,\n",
        "    max_mix_idx=max_mix_idx)\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(38, name='preprediction')(x)\n",
        "  predictions = Activation('softmax',name='prediction')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "  optimizer = 'sgd',\n",
        "  metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1lHVDc082Z"
      },
      "source": [
        "train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(seed=7, root_dir=data_dir, lab=False, \n",
        "  verbose=Verbose, bipolar=False, base_model_name='plant_leaf',\n",
        "  training_size=0.6, validation_size=0.2, test_size=0.2,\n",
        "  target_size=(input_shape[0],input_shape[1]), \n",
        "  has_training=True, has_validation=True, has_testing=True, \n",
        "  smart_resize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UosoQy_c1_4M"
      },
      "source": [
        "print(train_x.shape,val_x.shape,test_x.shape)\n",
        "print(train_y.shape,val_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-q_V3dJ3BhT"
      },
      "source": [
        "for max_mix_idx in [5]: # range(-1,10,1):\n",
        "    basefilename = 'Schuler-baseline-v2.7-'+str(max_mix_idx)\n",
        "    print('Running: '+basefilename)\n",
        "    model = compiled_two_path_inception_v3(\n",
        "      classes=38,\n",
        "      input_shape=input_shape,\n",
        "      two_paths_first_block=False,\n",
        "      two_paths_second_block=False,\n",
        "      max_mix_idx=max_mix_idx)\n",
        "    best_result_file_name = basefilename+'-best-result.hdf5'\n",
        "    save_best = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=best_result_file_name, \n",
        "      monitor=monitor, \n",
        "      verbose=1, \n",
        "      save_best_only=True, \n",
        "      save_weights_only=False, \n",
        "      mode='max', \n",
        "      save_freq='epoch')\n",
        "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size,\n",
        "      validation_data=(val_x,val_y),\n",
        "      callbacks=[save_best], \n",
        "      class_weight = classweight\n",
        "    )\n",
        "    print('Testing Last Model: '+basefilename)\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Best Model Results: '+basefilename)\n",
        "    model = keras.models.load_model(best_result_file_name, custom_objects={'CopyChannels': cai.layers.CopyChannels})\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Finished: '+basefilename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
