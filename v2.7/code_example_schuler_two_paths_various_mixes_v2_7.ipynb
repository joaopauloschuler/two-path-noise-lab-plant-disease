{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code_example_schuler_two_paths_various_mixes-v2.7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "monitor='val_accuracy'\n",
        "epochs=30\n",
        "batch_size=16\n",
        "input_shape=(128, 128, 3) # please resize it to (224,224,3) if you have enough RAM\n",
        "Verbose=True"
      ],
      "metadata": {
        "id": "6DH0gsiwyxgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXWocLnz38N"
      },
      "source": [
        "This source code requires a **HIGH RAM** machine.\n",
        "\n",
        "You might need to install this on your system:\n",
        "\n",
        "apt-get install python3-opencv git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQKpflNl7m63"
      },
      "source": [
        "import os\n",
        "!rm -r k\n",
        "if not os.path.isdir('k'):\n",
        "  !git clone -b development14 https://github.com/joaopauloschuler/k-neural-api.git k\n",
        "else:\n",
        "  !cd k && git pull\n",
        "\n",
        "!cd k && pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWmCCX96ndE"
      },
      "source": [
        "import sys\n",
        "print(\"Python version\")\n",
        "print (sys.version)\n",
        "print(\"Version info.\")\n",
        "print (sys.version_info)\n",
        "\n",
        "import skimage\n",
        "print('skimage version',  skimage.__version__)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "import cai\n",
        "import cai.datasets\n",
        "import cai.densenet\n",
        "import cai.util\n",
        "import cai.models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WqdOtor61VZ"
      },
      "source": [
        "url_zip_file=\"https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/file_downloaded\"\n",
        "local_zip_file=\"plant_leaf.zip\"\n",
        "expected_folder_name=\"plant_leaf\"\n",
        "cai.datasets.download_zip_and_extract(\n",
        "    url_zip_file=url_zip_file, local_zip_file=local_zip_file, \n",
        "    expected_folder_name=expected_folder_name, Verbose=Verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yn9mmLAxvlK"
      },
      "source": [
        "import random\n",
        "import os\n",
        "import multiprocessing\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.utils.class_weight\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2LGtzGBx5IR"
      },
      "source": [
        "!rm -r plant_leaf/Plant_leave_diseases_dataset_without_augmentation/Background_without_leaves -R\n",
        "data_dir = \"plant_leaf/Plant_leave_diseases_dataset_without_augmentation/\"\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1lHVDc082Z"
      },
      "source": [
        "train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(seed=7, root_dir=data_dir, lab=True, \n",
        "  verbose=Verbose, bipolar=False, base_model_name='plant_leaf',\n",
        "  training_size=0.6, validation_size=0.2, test_size=0.2,\n",
        "  target_size=(input_shape[0],input_shape[1]), \n",
        "  has_training=True, has_validation=True, has_testing=True, \n",
        "  smart_resize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UosoQy_c1_4M"
      },
      "source": [
        "print(train_x.shape,val_x.shape,test_x.shape)\n",
        "print(train_y.shape,val_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-q_V3dJ3BhT"
      },
      "source": [
        "for two_paths_second_block in [False]:\n",
        "  for l_ratio in [0.2]:\n",
        "    basefilename = 'two-path-inception-v2.7-'+str(two_paths_second_block)+'-'+str(l_ratio)\n",
        "    print('Running: '+basefilename)\n",
        "    model = cai.models.compiled_two_path_inception_v3(\n",
        "      input_shape=input_shape,\n",
        "      classes=38, \n",
        "      two_paths_first_block=True,\n",
        "      two_paths_second_block=two_paths_second_block,\n",
        "      l_ratio=l_ratio,\n",
        "      ab_ratio=(1-l_ratio),\n",
        "      max_mix_idx=5, \n",
        "      model_name='two_path_inception_v3'\n",
        "      )    \n",
        "    monitor='val_accuracy'\n",
        "    best_result_file_name = basefilename+'-best_result.hdf5'\n",
        "    save_best = keras.callbacks.ModelCheckpoint(\n",
        "      filepath=best_result_file_name, \n",
        "      monitor=monitor, \n",
        "      verbose=1, \n",
        "      save_best_only=True, \n",
        "      save_weights_only=False, \n",
        "      mode='max', \n",
        "      period=1)\n",
        "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size,\n",
        "      validation_data=(val_x,val_y),\n",
        "      callbacks=[save_best],class_weight=classweight,\n",
        "      workers=multiprocessing.cpu_count())\n",
        "    print('Testing Last Model: '+basefilename)\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Best Model Results: '+basefilename)\n",
        "    model = keras.models.load_model(best_result_file_name, custom_objects={'CopyChannels': cai.layers.CopyChannels})\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    cai.models.save_model(model, basefilename)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Finished: '+basefilename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}